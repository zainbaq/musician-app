<html>
<head>
	<link href="css/style.css" rel="stylesheet" type="text/css">
	<title>Music App</title>
	{{!-- <script src="../public/js/microphone.js"></script> --}}
	{{!-- <script src="../public/js/tuner.js"></script> --}}
</head>
<body>
<header>
	
    <div class="container">
		
        <img src="../assets/img/clef.png" alt="logo" class="logo">

        <nav>
            <ul>
                <li><a href="/">Home</a></li>
                {{!-- <li><a href="tools">Tools</a></li> --}}
                <li><a href="/about">About</a></li>
                <li><a href="/login">Login</a></li>
                {{!-- <li><a href="#">Sign Up</a></li> --}}

            </li>
            </ul>
        </nav>
    </div>
</header>

<h2>
	<div class="jumbotron">
		<p>Tuner</p>
	</div>
</h2>

<div id="tune-box">
	<canvas id="spectum-canvas"></canvas>
</div>
{{!-- Perhaps button is unnecessary --}}

{{!-- <div id="tune-box">
	<button id="tune-button" onclick="new Microphone()" type="button">Click Here to Tune!</button>
</div> --}}

<div class="footer">
	<p> This application was developed to aid musicians on the quest to creative glory.</p>
</div>

<script src="../public/js/microphone.js"></script>
<script>
	function Microphone(fft) {
		var FFT_SIZE = fft || 1024;
		this.spectrum = [];
		this.volume = this.vol = 0;
		this.peak_volume = 0;
		var self = this;

		var audioContext = new AudioContext();
		var SAMPLE_RATE = audioContext.sampleRate;

		// Browser checker
		window.AudioContext = window.AudioContext || window.webkitAudioContext;
		navigator.getUserMedia = navigator.getUserMedia || navigator.webkitGetUserMedia;
		window.addEventListener('load', init, false);
		
		function init() {
			try {
				startMic(new AudioContext());
			} catch (e) {
				console.error(e)
				alert('Web Audio API is not suported in this browser');
			}
		}

		function startMic(context) {
			alert("Microphone is active");
			let constraintObj = {
				audio:true,
				video:false,
			}
			navigator.getUserMedia(constraintObj, processSound, error);
			function processSound(stream) {
				var analyser = context.createAnalyser();
				analyser.smoothingTimeConstant = 0.2;
				analyser.fftsize = FFT_SIZE;

				var node = context.createScriptProcessor(FFT_SIZE*2,1,1);
				node.onaudioprocess = function () {
					self.spectrum = new Uint8Array(analyser.frequencyBinCount);
					analyser.getByteFrequencyData(self.spectrum);
					// 
				
				self.vol = getRMS(self.spectrum);
				if (self.vol > self.peak_volume){self.peak_volume = self.vol};
				self.volume = self.vol;
				};

				var input = context.createMediaStreamSource(stream);
				input.connect(analyser);
				analyser.connect(node);
				node.connect(context.destination);


			}
			function error () {
				console.log(arguments);
			}
			function getRMS(spectrum) {
				var rms = 0;
				for (var i = 0; i < this.vols.length; i++) {
					rms += spectrum[i] * spectrum[i];
				}
				rms /= spectrum.length;
				rms = Math.sqrt(rms);
				return rms;
			}
		}
		return this
	}
	var mic = new Microphone();
	console.log(mic.spectrum);

	var canvas = document.getElementById("tune-canvas");
	canvas.background(235);
	function draw() {
		var s = Mic.getRMS();
		canvas.fillStyle = rgb(s*2);
		canvas.HfillEllipse(w/2,h/2,s*5,s*5);
	}
	
</script>
</body>


</html>
